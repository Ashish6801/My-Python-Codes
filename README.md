# My-Python-Codes

# Job-Posting = Web Scrapping
1. Import necessary libraries
2. Define the URL of the page to be scraped
3. Define a function named findJobs() to extract job listings
4. Initialize job count to zero
5. Get the HTML content of the page
6. Parse the HTML content using BeautifulSoup
7. Find all the job listings in the HTML content
8. Open a file to save job listings
9. Loop through each job listing and extract relevant information
10. Increment job count for each job found
11. Write job information to the file
12. Return the job count
13. Print the URL of the page being scraped
14. Call the findJobs() function to fetch and display job listings
15. Print the number of new jobs found
16. End of program

# ReLU = Deep Learning
1. Define the input and weights
2. Define the function to make a prediction with the network
3. Calculate node 0 in the first hidden layer
4. Calculate node 1 in the first hidden layer
5. Put node values into array: hidden_0_outputs
6. Calculate node 0 in the second hidden layer
7. Calculate node 1 in the second hidden layer
8. Put node values into array: hidden_1_outputs
9. Calculate model output: model_output
10. Return model_output
11. Call the predict_with_network() function and print the output
